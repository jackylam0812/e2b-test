#!/usr/bin/env python3
"""
E2Bæ²™ç®±ç”Ÿå‘½å‘¨æœŸæµ‹è¯•è„šæœ¬

æµ‹è¯•æŒ‡æ ‡:
- å†·å¯åŠ¨å»¶è¿Ÿï¼ˆæ¯æ¬¡é‡å¯ orchestratorï¼‰
- çƒ­å¯åŠ¨å»¶è¿Ÿï¼ˆæ¨¡æ¿ç¼“å­˜ + è¿›ç¨‹æ± é¢„çƒ­ï¼‰

ç¯å¢ƒå˜é‡ (å¿…é¡»é€šè¿‡ .e2b_env é…ç½®):
- E2B_DOMAIN: E2B æœåŠ¡åŸŸå (å¿…éœ€)
- E2B_API_KEY: E2B API å¯†é’¥ (å¿…éœ€)
- E2B_ORCHESTRATOR_JOB: Nomad orchestrator job åç§° (é»˜è®¤: orchestrator)
- NOMAD_ADDR: Nomad æœåŠ¡åœ°å€ (å†·å¯åŠ¨æµ‹è¯•éœ€è¦)
- NOMAD_TOKEN: Nomad è®¿é—®ä»¤ç‰Œ (å†·å¯åŠ¨æµ‹è¯•éœ€è¦)

ä½¿ç”¨æ–¹æ³•:
  source .e2b_env
  python3 01_sandbox_lifecycle.py --test cold --iterations 3
"""

import os
import sys
import ssl
import time
import json
import statistics
from typing import List, Dict

# ========== ç¦ç”¨ SSL è¯ä¹¦éªŒè¯ ==========
# è®¾ç½®æ‰€æœ‰å¯èƒ½çš„ç¯å¢ƒå˜é‡
os.environ['PYTHONHTTPSVERIFY'] = '0'
os.environ['CURL_CA_BUNDLE'] = ''
os.environ['REQUESTS_CA_BUNDLE'] = ''
os.environ['SSL_CERT_FILE'] = ''
os.environ['SSL_CERT_DIR'] = ''
os.environ['REQUESTS_VERIFY'] = 'false'

# åˆ›å»ºä¸éªŒè¯è¯ä¹¦çš„ SSL ä¸Šä¸‹æ–‡ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ä»»ä½•ç½‘ç»œåº“ä¹‹å‰ï¼‰
ssl._create_default_https_context = ssl._create_unverified_context

# æ›´åº•å±‚çš„æ–¹æ³•ï¼šæ‹¦æˆª SSLContext çš„åˆ›å»º
_original_create_default_context = ssl.create_default_context
def _patched_create_default_context(*args, **kwargs):
    ctx = _original_create_default_context(*args, **kwargs)
    ctx.check_hostname = False
    ctx.verify_mode = ssl.CERT_NONE
    return ctx
ssl.create_default_context = _patched_create_default_context

# æ‹¦æˆª SSLContext çš„ wrap_socket æ–¹æ³•ï¼Œç¡®ä¿æ‰€æœ‰ SSL è¿æ¥éƒ½ä¸éªŒè¯è¯ä¹¦
_original_wrap_socket = ssl.SSLContext.wrap_socket
def _patched_wrap_socket(self, sock, server_side=False, do_handshake_on_connect=True,
                        suppress_ragged_eofs=True, server_hostname=None, session=None):
    # ç¡®ä¿ä¸éªŒè¯è¯ä¹¦
    self.check_hostname = False
    self.verify_mode = ssl.CERT_NONE
    return _original_wrap_socket(
        self, sock, server_side=server_side,
        do_handshake_on_connect=do_handshake_on_connect,
        suppress_ragged_eofs=suppress_ragged_eofs,
        server_hostname=server_hostname, session=session
    )
ssl.SSLContext.wrap_socket = _patched_wrap_socket

# ç¦ç”¨ SSL è­¦å‘Š
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å°è¯•é…ç½® requestsï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    import requests
    requests.packages.urllib3.disable_warnings()
except (ImportError, AttributeError):
    pass

# å°è¯•é…ç½® httpxï¼ˆå¦‚æœå­˜åœ¨ï¼‰
try:
    import httpx
    # æ‹¦æˆª httpx çš„ Client å’Œ AsyncClient åˆå§‹åŒ–
    _original_httpx_client_init = httpx.Client.__init__
    def _patched_httpx_client_init(self, *args, verify=False, **kwargs):
        return _original_httpx_client_init(self, *args, verify=False, **kwargs)
    httpx.Client.__init__ = _patched_httpx_client_init
    
    _original_httpx_async_client_init = httpx.AsyncClient.__init__
    def _patched_httpx_async_client_init(self, *args, verify=False, **kwargs):
        return _original_httpx_async_client_init(self, *args, verify=False, **kwargs)
    httpx.AsyncClient.__init__ = _patched_httpx_async_client_init
except (ImportError, AttributeError):
    pass

# å¯¼å…¥ E2B SDK å’Œå…¶ä»–ä¾èµ–
from e2b import Sandbox

# å¯¼å…¥å½©è‰²æ—¥å¿—
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.logger import get_logger

logger = get_logger(__name__)
import subprocess

# æ£€æŸ¥å¿…éœ€çš„ç¯å¢ƒå˜é‡
required_env_vars = ['E2B_DOMAIN', 'E2B_API_KEY']
missing_vars = [var for var in required_env_vars if var not in os.environ]
if missing_vars:
    logger.error(f"é”™è¯¯: ç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡: {', '.join(missing_vars)}")
    logger.info("è¯·å…ˆè¿è¡Œ: source .e2b_env")
    sys.exit(1)

# è®¾ç½®é»˜è®¤å€¼ï¼ˆå¦‚æœæœªè®¾ç½®ï¼‰
os.environ.setdefault('E2B_ORCHESTRATOR_JOB', 'orchestrator')


def restart_nomad_orchestrator(job_name: str, wait_time: int = 30) -> bool:
    """
    é‡å¯ Nomad orchestrator job ä»¥ç¡®ä¿çœŸæ­£çš„å†·å¯åŠ¨

    Args:
        job_name: Nomad job åç§°
        wait_time: é‡å¯åç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        æ˜¯å¦æˆåŠŸé‡å¯
    """
    logger.info(f"\n{'='*60}")
    logger.info(f"é‡å¯ Nomad Orchestrator: {job_name}")
    logger.info(f"{'='*60}")

    nomad_addr = os.getenv('NOMAD_ADDR')
    nomad_token = os.getenv('NOMAD_TOKEN')

    logger.info(f"Nomad åœ°å€: {nomad_addr}")
    logger.info(f"Job åç§°: {job_name}")

    try:
        # æ„å»º nomad å‘½ä»¤
        nomad_cmd = ['nomad', 'job', 'restart']

        # æ·»åŠ  -address å‚æ•°
        if nomad_addr:
            nomad_cmd.extend(['-address', nomad_addr])

        # æ·»åŠ  -token å‚æ•°
        if nomad_token:
            nomad_cmd.extend(['-token', nomad_token])

        # æ·»åŠ è‡ªåŠ¨ç¡®è®¤å‚æ•°ï¼ˆéäº¤äº’å¼ï¼‰
        nomad_cmd.append('-yes')
        nomad_cmd.append('-on-error=fail')

        # æ·»åŠ  job åç§°
        nomad_cmd.append(job_name)

        logger.info(f"\næ‰§è¡Œå‘½ä»¤: {' '.join(nomad_cmd[:3])} ... {job_name}")
        logger.info("é‡å¯ä¸­...")

        # æ‰§è¡Œé‡å¯å‘½ä»¤
        result = subprocess.run(
            nomad_cmd,
            capture_output=True,
            text=True,
            timeout=60
        )

        if result.returncode == 0:
            logger.info("âœ“ æˆåŠŸ")
            logger.info(f"\nç­‰å¾… orchestrator å°±ç»ª ({wait_time} ç§’)...")

            # æ˜¾ç¤ºè¿›åº¦æ¡
            for i in range(wait_time):
                time.sleep(1)
                progress = int((i + 1) / wait_time * 50)
                bar = 'â–ˆ' * progress + 'â–‘' * (50 - progress)
                logger.info(f"\r  [{bar}] {i+1}/{wait_time}s")

            logger.info("\nâœ“ Orchestrator å·²å°±ç»ª")
            logger.info(f"{'='*60}\n")
            return True
        else:
            logger.error("âœ— å¤±è´¥")
            logger.error(f"\né”™è¯¯ä¿¡æ¯:")
            logger.info(result.stderr)
            return False

    except subprocess.TimeoutExpired:
        logger.error("âœ— è¶…æ—¶")
        logger.info("\né‡å¯å‘½ä»¤æ‰§è¡Œè¶…æ—¶ (60ç§’)")
        return False

    except FileNotFoundError:
        logger.error("âœ— å¤±è´¥")
        logger.error("\né”™è¯¯: æœªæ‰¾åˆ° 'nomad' å‘½ä»¤")
        logger.info("è¯·ç¡®ä¿ Nomad CLI å·²å®‰è£…å¹¶åœ¨ PATH ä¸­")
        return False

    except Exception as e:
        logger.error("âœ— å¤±è´¥")
        logger.info(f"\nå¼‚å¸¸: {e}")
        return False


def test_cold_start_latency(iterations: int = 10, template: str = None) -> Dict:
    """
    æµ‹è¯•å†·å¯åŠ¨å»¶è¿Ÿ

    æ³¨æ„: å†·å¯åŠ¨æµ‹è¯•ä¼šåœ¨æ¯æ¬¡æµ‹è¯•å‰é‡å¯ orchestratorï¼Œç¡®ä¿çœŸæ­£çš„å†·å¯åŠ¨ã€‚
    Orchestrator job åç§°ä»ç¯å¢ƒå˜é‡ E2B_ORCHESTRATOR_JOB è·å–ï¼ˆé»˜è®¤: orchestratorï¼‰

    Args:
        iterations: æµ‹è¯•æ¬¡æ•°
        template: æ¨¡æ¿ID(å¯é€‰)

    Returns:
        åŒ…å«ç»Ÿè®¡æ•°æ®çš„å­—å…¸
    """
    # è·å– orchestrator job åç§°
    orchestrator_job = os.getenv('E2B_ORCHESTRATOR_JOB', 'orchestrator')

    logger.info(f"å¼€å§‹æµ‹è¯•å†·å¯åŠ¨å»¶è¿Ÿ (è¿­ä»£{iterations}æ¬¡)...")
    logger.info(f"ğŸ’¡ æ¯æ¬¡æµ‹è¯•å‰é‡å¯ orchestrator: {orchestrator_job}")
    logger.warning(f"âš ï¸  é¢„è®¡è€—æ—¶: çº¦ {int((30 + 10) * iterations / 60)} åˆ†é’Ÿ\n")

    cold_start_latencies = []

    for i in range(iterations):
        # æ¯æ¬¡æµ‹è¯•å‰éƒ½é‡å¯ orchestratorï¼ˆçœŸå†·å¯åŠ¨ï¼‰
        logger.info(f"\n{'â”€'*60}")
        logger.info(f"ç¬¬ {i+1}/{iterations} æ¬¡çœŸå†·å¯åŠ¨æµ‹è¯•")
        logger.info(f"{'â”€'*60}")
        success = restart_nomad_orchestrator(orchestrator_job, wait_time=30)
        if not success:
            logger.error(f"âš ï¸  é‡å¯å¤±è´¥ï¼Œè·³è¿‡ç¬¬ {i+1} æ¬¡æµ‹è¯•\n")
            continue

        logger.info(f"  æµ‹è¯• {i+1}/{iterations}...")

        start_time = time.time()

        try:
            # åˆ›å»ºæ²™ç®±ï¼ˆä¸æŒ‡å®šæ¨¡æ¿ä½¿ç”¨é»˜è®¤ï¼‰
            if template:
                sandbox = Sandbox(template)
            else:
                sandbox = Sandbox()

            # Sandbox åˆ›å»ºæˆåŠŸå³è¡¨ç¤ºå°±ç»ª
            # ï¼ˆä¸æ‰§è¡Œé¢å¤–å‘½ä»¤ï¼Œé¿å… streaming response é—®é¢˜ï¼‰

            end_time = time.time()
            latency_ms = (end_time - start_time) * 1000

            cold_start_latencies.append(latency_ms)
            logger.info(f"{latency_ms:.2f} ms [çœŸå†·å¯åŠ¨ #{i+1}]")

            # å…³é—­æ²™ç®±
            sandbox.kill()

        except Exception as e:
            logger.error(f"å¤±è´¥: {e}")
            continue
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    if not cold_start_latencies:
        return {"error": "æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥"}

    cold_start_latencies.sort()
    n = len(cold_start_latencies)

    stats = {
        "raw_data": cold_start_latencies,
        "count": n,
        "min": min(cold_start_latencies),
        "max": max(cold_start_latencies),
        "mean": statistics.mean(cold_start_latencies),
        "median": statistics.median(cold_start_latencies),
        "stdev": statistics.stdev(cold_start_latencies) if n > 1 else 0,
        "p50": cold_start_latencies[int(n * 0.50)],
        "p95": cold_start_latencies[int(n * 0.95)],
        "p99": cold_start_latencies[int(n * 0.99)] if n >= 100 else cold_start_latencies[-1],
    }

    stats["note"] = "çœŸå†·å¯åŠ¨ï¼ˆæ¯æ¬¡é‡å¯ orchestratorï¼‰"
    logger.info(f"\nğŸ¥¶ çœŸå†·å¯åŠ¨ç»Ÿè®¡ï¼ˆ{n} æ¬¡ï¼Œæ¯æ¬¡é‡å¯ orchestratorï¼‰:")

    logger.info(f"  æœ€å°å€¼: {stats['min']:.2f} ms")
    logger.info(f"  æœ€å¤§å€¼: {stats['max']:.2f} ms")
    logger.info(f"  å¹³å‡å€¼: {stats['mean']:.2f} ms â­")
    logger.info(f"  ä¸­ä½æ•°: {stats['median']:.2f} ms")
    logger.info(f"  P50: {stats['p50']:.2f} ms")
    logger.info(f"  P95: {stats['p95']:.2f} ms")
    logger.info(f"  P99: {stats['p99']:.2f} ms")
    logger.info(f"  æ ‡å‡†å·®: {stats['stdev']:.2f} ms")

    return stats


def test_warm_start_latency(iterations: int = 10, template: str = None) -> Dict:
    """
    æµ‹è¯•çƒ­å¯åŠ¨å»¶è¿Ÿï¼ˆèŠ‚ç‚¹ç¼“å­˜ + è¿›ç¨‹æ± å¤ç”¨ï¼‰

    é¢„çƒ­ç­–ç•¥: å…ˆåˆ›å»ºå¹¶å…³é—­ä¸€ä¸ªæ²™ç®±ï¼Œè®©ç³»ç»Ÿç¼“å­˜æ¨¡æ¿å’Œé¢„çƒ­è¿›ç¨‹æ± ã€‚
    ä¸å†·å¯åŠ¨çš„åŒºåˆ«ï¼š
    - å†·å¯åŠ¨: ç¬¬1æ¬¡æµ‹è¯•ï¼ˆæ‹‰å–æ¨¡æ¿ï¼‰vs ç¬¬2+æ¬¡ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
    - çƒ­å¯åŠ¨: é¢„çƒ­åè¿ç»­æµ‹è¯•ï¼ˆæ¨¡æ¿ç¼“å­˜ + è¿›ç¨‹æ± çƒ­ï¼‰

    Args:
        iterations: æµ‹è¯•æ¬¡æ•°
        template: æ¨¡æ¿ID(å¯é€‰)

    Returns:
        åŒ…å«ç»Ÿè®¡æ•°æ®çš„å­—å…¸
    """
    logger.info(f"å¼€å§‹æµ‹è¯•çƒ­å¯åŠ¨å»¶è¿Ÿ (è¿­ä»£{iterations}æ¬¡)...")
    logger.info("ğŸ’¡ çƒ­å¯åŠ¨ = æ¨¡æ¿å·²ç¼“å­˜ + è¿›ç¨‹æ± å·²é¢„çƒ­\n")
    
    # é¢„çƒ­: åˆ›å»ºå¹¶å…³é—­ä¸€ä¸ªæ²™ç®±
    logger.info("  é¢„çƒ­ä¸­...")
    try:
        if template:
            warmup_sandbox = Sandbox(template)
        else:
            warmup_sandbox = Sandbox()
        warmup_sandbox.kill()
        time.sleep(2)
        logger.info("  é¢„çƒ­å®Œæˆ")
    except Exception as e:
        logger.error(f"  é¢„çƒ­å¤±è´¥: {e}")
    
    latencies = []
    
    for i in range(iterations):
        logger.info(f"  æµ‹è¯• {i+1}/{iterations}...")
        
        start_time = time.time()
        
        try:
            # åˆ›å»ºæ²™ç®±ï¼ˆä¸æŒ‡å®šæ¨¡æ¿ä½¿ç”¨é»˜è®¤ï¼‰
            if template:
                sandbox = Sandbox(template)
            else:
                sandbox = Sandbox()

            # Sandbox åˆ›å»ºæˆåŠŸå³è¡¨ç¤ºå°±ç»ª
            # ï¼ˆä¸æ‰§è¡Œé¢å¤–å‘½ä»¤ï¼Œé¿å… streaming response é—®é¢˜ï¼‰
            
            end_time = time.time()
            latency_ms = (end_time - start_time) * 1000
            latencies.append(latency_ms)
            
            logger.info(f"{latency_ms:.2f} ms")
            
            # å…³é—­æ²™ç®±
            sandbox.kill()
            
        except Exception as e:
            logger.error(f"å¤±è´¥: {e}")
            continue
        
        # çŸ­æš‚ç­‰å¾…
        time.sleep(0.5)
    
    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    if not latencies:
        return {"error": "æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥"}
    
    latencies.sort()
    n = len(latencies)
    
    stats = {
        "raw_data": latencies,
        "count": n,
        "min": min(latencies),
        "max": max(latencies),
        "mean": statistics.mean(latencies),
        "median": statistics.median(latencies),
        "stdev": statistics.stdev(latencies) if n > 1 else 0,
        "p50": latencies[int(n * 0.50)],
        "p95": latencies[int(n * 0.95)],
        "p99": latencies[int(n * 0.99)] if n >= 100 else latencies[-1],
    }
    
    logger.info("\nç»Ÿè®¡ç»“æœ:")
    logger.info(f"  P50: {stats['p50']:.2f} ms â­")
    logger.info(f"  P95: {stats['p95']:.2f} ms")
    logger.info(f"  P99: {stats['p99']:.2f} ms")
    
    return stats



def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="E2Bæ²™ç®±ç”Ÿå‘½å‘¨æœŸæµ‹è¯•")
    parser.add_argument("--test", choices=["cold", "warm", "all"],
                       default="all", help="æµ‹è¯•ç±»å‹")
    parser.add_argument("--iterations", type=int, default=10, help="æµ‹è¯•è¿­ä»£æ¬¡æ•°")
    parser.add_argument("--template", type=str, help="æ¨¡æ¿ID")
    parser.add_argument("--output", type=str, help="è¾“å‡ºJSONæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    results = {}
    
    # å†·å¯åŠ¨æµ‹è¯•ï¼ˆæ¯æ¬¡é‡å¯ orchestratorï¼‰
    if args.test in ["cold", "all"]:
        results["cold_start"] = test_cold_start_latency(args.iterations, args.template)
        logger.info("\n" + "="*60 + "\n")
    
    # çƒ­å¯åŠ¨æµ‹è¯•
    if args.test in ["warm", "all"]:
        results["warm_start"] = test_warm_start_latency(args.iterations, args.template)
        logger.info("\n" + "="*60 + "\n")

    # ä¿å­˜ç»“æœ
    if args.output:
        with open(args.output, 'w') as f:
            json.dump(results, f, indent=2)
        logger.info(f"ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
    
    return results


if __name__ == "__main__":
    main()
