"""
æ–‡ä»¶ç®¡ç†æœåŠ¡ - FastAPIå¼‚æ­¥å®ç°
åŠŸèƒ½ï¼š
1. /health - å¥åº·æ£€æŸ¥
2. /sum - è¿”å›æ–‡ä»¶æ•°é‡
3. /action - åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥æ¨¡æ‹Ÿæ–°é—»å†…å®¹ï¼Œæ”¯æŒæ–‡ä»¶æ•°é‡ç®¡ç†
4. /search - ä½¿ç”¨æµè§ˆå™¨è®¿é—® Google å¹¶è¿›è¡Œéšæœºæœç´¢
5. /terminal - æ‰§è¡Œéšæœºç»ˆç«¯å‘½ä»¤
6. /network - æ‰§è¡Œç½‘ç»œ I/O æ“ä½œ
"""

from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
import aiofiles
import asyncio
import os
import random
import subprocess
import httpx
from datetime import datetime
from pathlib import Path
from typing import Optional, List
from playwright.async_api import async_playwright, Browser, Page

# FastAPIåº”ç”¨å®ä¾‹
app = FastAPI(
    title="æ–‡ä»¶ç®¡ç†æœåŠ¡",
    description="åŸºäºFastAPIçš„å¼‚æ­¥æ–‡ä»¶ç®¡ç†æœåŠ¡ï¼Œæ”¯æŒå¹¶å‘å®‰å…¨çš„æ–‡ä»¶åˆ›å»ºå’Œç®¡ç†",
    version="1.0.0"
)

# é…ç½®
FILE_DIR = "/home/ubuntu/"
MAX_FILES = 10

# â­ æ— é”è®¾è®¡ï¼šæœ€å¤§åŒ–å¹¶å‘æ€§èƒ½
# æ³¨æ„ï¼šåœ¨é«˜å¹¶å‘åœºæ™¯ä¸‹ï¼Œæ–‡ä»¶æ•°é‡å¯èƒ½æš‚æ—¶è¶…è¿‡MAX_FILES
# è¿™æ˜¯æ€§èƒ½å’Œä¸€è‡´æ€§ä¹‹é—´çš„æƒè¡¡

# æ¨¡æ‹Ÿæ–°é—»æ ‡é¢˜å’Œå†…å®¹æ¨¡æ¿
NEWS_TITLES = [
    "ç§‘æŠ€å·¨å¤´å‘å¸ƒæœ€æ–°AIäº§å“",
    "å…¨çƒæ°”å€™å³°ä¼šè¾¾æˆé‡è¦åè®®",
    "ç»æµæ•°æ®æ˜¾ç¤ºå¢é•¿åŠ¿å¤´å¼ºåŠ²",
    "ä½“è‚²èµ›äº‹åˆ›ä¸‹æ”¶è§†æ–°é«˜",
    "æ–‡åŒ–å±•è§ˆå¸å¼•å¤§é‡è§‚ä¼—",
    "å¥åº·ç ”ç©¶æ­ç¤ºæ–°å‘ç°",
    "æ•™è‚²æ”¹é©æ–¹æ¡ˆæ­£å¼å®æ–½",
    "äº¤é€šåŸºç¡€è®¾æ–½å»ºè®¾åŠ é€Ÿ",
    "ç¯ä¿å€¡è®®è·å¾—å¹¿æ³›æ”¯æŒ",
    "å›½é™…åˆä½œé¡¹ç›®å–å¾—çªç ´"
]

NEWS_CATEGORIES = ["ç§‘æŠ€", "è´¢ç»", "ä½“è‚²", "æ–‡åŒ–", "å¥åº·", "æ•™è‚²", "ç¤¾ä¼š", "å›½é™…"]

# éšæœºæœç´¢å…³é”®è¯åˆ—è¡¨
SEARCH_KEYWORDS = [
    "äººå·¥æ™ºèƒ½æœ€æ–°å‘å±•",
    "é‡å­è®¡ç®—æœº",
    "æ°”å€™å˜åŒ–è§£å†³æ–¹æ¡ˆ",
    "å¤ªç©ºæ¢ç´¢æ–°é—»",
    "å¯å†ç”Ÿèƒ½æºæŠ€æœ¯",
    "æœºå™¨å­¦ä¹ åº”ç”¨",
    "åŒºå—é“¾æŠ€æœ¯",
    "å…ƒå®‡å®™å‘å±•",
    "ç”Ÿç‰©ç§‘æŠ€çªç ´",
    "è‡ªåŠ¨é©¾é©¶æ±½è½¦"
]

# éšæœºç»ˆç«¯å‘½ä»¤åˆ—è¡¨
TERMINAL_COMMANDS = [
    {"cmd": ["pwd"], "description": "æ˜¾ç¤ºå½“å‰å·¥ä½œç›®å½•"},
    {"cmd": ["whoami"], "description": "æ˜¾ç¤ºå½“å‰ç”¨æˆ·"},
    {"cmd": ["date"], "description": "æ˜¾ç¤ºå½“å‰æ—¥æœŸå’Œæ—¶é—´"},
    {"cmd": ["uname", "-a"], "description": "æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯"},
    {"cmd": ["df", "-h"], "description": "æ˜¾ç¤ºç£ç›˜ä½¿ç”¨æƒ…å†µ"},
    {"cmd": ["free", "-m"], "description": "æ˜¾ç¤ºå†…å­˜ä½¿ç”¨æƒ…å†µ"},
    {"cmd": ["uptime"], "description": "æ˜¾ç¤ºç³»ç»Ÿè¿è¡Œæ—¶é—´"},
    {"cmd": ["ls", "-la", "/home/ubuntu"], "description": "åˆ—å‡º ubuntu ä¸»ç›®å½•æ–‡ä»¶"},
    {"cmd": ["python", "--version"], "description": "æ˜¾ç¤º Python ç‰ˆæœ¬"},
    {"cmd": ["echo", "Hello from terminal!"], "description": "è¾“å‡ºé—®å€™ä¿¡æ¯"}
]

# ç½‘ç»œ I/O æµ‹è¯•é…ç½®ï¼ˆå…¨éƒ¨ä¸ºäº’è”ç½‘å…¬ç½‘åœ°å€ï¼‰
NETWORK_TEST_URLS = [
    # httpbin.org - å…¬å¼€çš„ HTTP æµ‹è¯•æœåŠ¡
    {
        "url": "https://httpbin.org/bytes/1048576",  # 1MB
        "description": "httpbin.org - ä¸‹è½½ 1MB éšæœºæ•°æ®",
        "size_mb": 1.0,
        "type": "download"
    },
    {
        "url": "https://httpbin.org/bytes/5242880",  # 5MB
        "description": "httpbin.org - ä¸‹è½½ 5MB éšæœºæ•°æ®",
        "size_mb": 5.0,
        "type": "download"
    },
    {
        "url": "https://httpbin.org/bytes/10485760",  # 10MB
        "description": "httpbin.org - ä¸‹è½½ 10MB éšæœºæ•°æ®",
        "size_mb": 10.0,
        "type": "download"
    },
    # å»¶è¿Ÿæµ‹è¯•
    {
        "url": "https://httpbin.org/delay/1",
        "description": "httpbin.org - 1ç§’å»¶è¿Ÿè¯·æ±‚ï¼ˆæµ‹è¯•å»¶è¿Ÿï¼‰",
        "size_mb": 0.001,
        "type": "latency"
    },
    {
        "url": "https://httpbin.org/delay/2",
        "description": "httpbin.org - 2ç§’å»¶è¿Ÿè¯·æ±‚ï¼ˆæµ‹è¯•å»¶è¿Ÿï¼‰",
        "size_mb": 0.001,
        "type": "latency"
    },
    # GitHub API - å…¨çƒ CDN
    {
        "url": "https://api.github.com/repos/python/cpython",
        "description": "GitHub API - Python ä»“åº“ä¿¡æ¯",
        "size_mb": 0.01,
        "type": "api"
    },
    {
        "url": "https://api.github.com/repos/microsoft/vscode",
        "description": "GitHub API - VSCode ä»“åº“ä¿¡æ¯",
        "size_mb": 0.01,
        "type": "api"
    },
    # JSONPlaceholder - å…¬å¼€æµ‹è¯• API
    {
        "url": "https://jsonplaceholder.typicode.com/posts",
        "description": "JSONPlaceholder - è·å–æ–‡ç« åˆ—è¡¨",
        "size_mb": 0.01,
        "type": "api"
    },
    {
        "url": "https://jsonplaceholder.typicode.com/users",
        "description": "JSONPlaceholder - è·å–ç”¨æˆ·åˆ—è¡¨",
        "size_mb": 0.005,
        "type": "api"
    },
    # Google å…¬å¼€æœåŠ¡
    {
        "url": "https://www.google.com",
        "description": "Google - é¦–é¡µï¼ˆHTMLï¼‰",
        "size_mb": 0.5,
        "type": "web"
    },
    # Wikipedia
    {
        "url": "https://en.wikipedia.org/wiki/Main_Page",
        "description": "Wikipedia - è‹±æ–‡é¦–é¡µ",
        "size_mb": 0.8,
        "type": "web"
    },
    # Cloudflare Speed Test
    {
        "url": "https://speed.cloudflare.com/__down?bytes=1000000",
        "description": "Cloudflare - ä¸‹è½½ 1MB æµ‹é€Ÿ",
        "size_mb": 1.0,
        "type": "download"
    }
]


def generate_mock_news() -> str:
    """
    ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»å†…å®¹

    Returns:
        str: æ ¼å¼åŒ–çš„æ–°é—»å†…å®¹
    """
    title = random.choice(NEWS_TITLES)
    category = random.choice(NEWS_CATEGORIES)
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    # ç”Ÿæˆéšæœºæ®µè½
    paragraphs = []
    num_paragraphs = random.randint(2, 4)

    for _ in range(num_paragraphs):
        sentences = []
        num_sentences = random.randint(3, 6)
        for _ in range(num_sentences):
            sentence = f"è¿™æ˜¯ä¸€æ¡å…³äº{category}çš„æ–°é—»å†…å®¹ï¼ŒåŒ…å«é‡è¦ä¿¡æ¯å’Œè¯¦ç»†æŠ¥é“ã€‚"
            sentences.append(sentence)
        paragraphs.append(" ".join(sentences))

    # æ·»åŠ æ–‡ä»¶åˆ›å»ºæ—¶é—´æˆ³ï¼ˆUTC+8ï¼‰
    create_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    create_timestamp_iso = datetime.now().isoformat()

    content = f"""
========================================
ğŸ“„ æ–‡ä»¶ä¿¡æ¯
========================================
æ–‡ä»¶åˆ›å»ºæ—¶é—´: {create_timestamp} (UTC+8)
åˆ›å»ºæ—¶é—´æˆ³: {create_timestamp_iso}

========================================
ğŸ“° æ–°é—»å†…å®¹
========================================
æ–°é—»æ ‡é¢˜ï¼š{title}
åˆ†ç±»ï¼š{category}
å‘å¸ƒæ—¶é—´ï¼š{timestamp}
========================================

{chr(10).join(paragraphs)}

----------------------------------------
æœ¬æ–‡ç”±æ–‡ä»¶ç®¡ç†æœåŠ¡è‡ªåŠ¨ç”Ÿæˆ
ç”Ÿæˆæ—¶é—´ï¼š{timestamp}
æ—¶åŒºï¼šUTC+8
========================================
"""
    return content


async def get_files_sorted_by_mtime() -> list[str]:
    """
    è·å–æ–‡ä»¶åˆ—è¡¨ï¼ŒæŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ—§çš„åœ¨å‰ï¼‰

    Returns:
        list[str]: æ’åºåçš„æ–‡ä»¶ååˆ—è¡¨
    """
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        Path(FILE_DIR).mkdir(parents=True, exist_ok=True)

        # è·å–æ‰€æœ‰æ–‡ä»¶
        files = [
            f for f in os.listdir(FILE_DIR)
            if os.path.isfile(os.path.join(FILE_DIR, f)) and f.startswith("news_")
        ]

        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼ˆæœ€æ—§çš„åœ¨å‰ï¼‰
        files.sort(key=lambda x: os.path.getmtime(os.path.join(FILE_DIR, x)))

        return files
    except Exception as e:
        print(f"è·å–æ–‡ä»¶åˆ—è¡¨å‡ºé”™: {e}")
        return []


@app.get("/health")
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£

    Returns:
        dict: å¥åº·çŠ¶æ€
    """
    return {"status": "ok"}


@app.get("/sum")
async def get_file_count():
    """
    è¿”å›å½“å‰æ–‡ä»¶æ•°é‡

    Returns:
        dict: åŒ…å«æ–‡ä»¶æ•°é‡å’Œè·¯å¾„çš„ä¿¡æ¯
    """
    try:
        files = await get_files_sorted_by_mtime()
        return {
            "count": len(files),
            "path": FILE_DIR,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡ä»¶æ•°é‡å¤±è´¥: {str(e)}")


@app.post("/action")
async def create_file_with_news():
    """
    åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥æ¨¡æ‹Ÿæ–°é—»å†…å®¹ï¼ˆæ— é”é«˜å¹¶å‘ç‰ˆæœ¬ï¼‰

    åŠŸèƒ½ï¼š
    1. æ£€æŸ¥å½“å‰æ–‡ä»¶æ•°é‡
    2. å¦‚æœæ–‡ä»¶æ•°é‡ >= 10ï¼Œå°è¯•åˆ é™¤æœ€æ—§çš„æ–‡ä»¶ï¼ˆåŸºäºmtimeï¼‰
    3. ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»å†…å®¹
    4. åˆ›å»ºæ–°æ–‡ä»¶å¹¶å†™å…¥å†…å®¹
    5. è¿”å›æ“ä½œç»“æœ

    æ³¨æ„ï¼š
    - æ— é”è®¾è®¡ï¼Œæ”¯æŒå®Œå…¨å¹¶å‘æ‰§è¡Œ
    - é«˜å¹¶å‘æ—¶æ–‡ä»¶æ•°é‡å¯èƒ½æš‚æ—¶è¶…è¿‡MAX_FILES
    - æœ€ç»ˆä¼šè¶‹å‘äºç»´æŒåœ¨MAX_FILESå·¦å³

    Returns:
        dict: æ“ä½œç»“æœï¼ŒåŒ…å«æ–‡ä»¶åã€åˆ é™¤çš„æ–‡ä»¶ç­‰ä¿¡æ¯
    """
    try:
        # æ­¥éª¤1: è·å–å½“å‰æ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰mtimeæ’åºï¼‰
        files = await get_files_sorted_by_mtime()
        deleted_file: Optional[str] = None

        # æ­¥éª¤2: æ£€æŸ¥å¹¶åˆ é™¤æœ€æ—§çš„æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if len(files) >= MAX_FILES:
            oldest_file = files[0]
            oldest_file_path = os.path.join(FILE_DIR, oldest_file)

            try:
                os.remove(oldest_file_path)
                deleted_file = oldest_file
                print(f"[å¹¶å‘åˆ é™¤] åˆ é™¤æœ€æ—§æ–‡ä»¶: {oldest_file}")
            except FileNotFoundError:
                # å¹¶å‘åœºæ™¯ï¼šæ–‡ä»¶å¯èƒ½å·²è¢«å…¶ä»–è¯·æ±‚åˆ é™¤ï¼Œè¿™æ˜¯æ­£å¸¸çš„
                print(f"[å¹¶å‘åˆ é™¤] æ–‡ä»¶å·²è¢«åˆ é™¤: {oldest_file}")
                deleted_file = f"{oldest_file} (å·²è¢«å…¶ä»–è¯·æ±‚åˆ é™¤)"
            except Exception as e:
                # å…¶ä»–åˆ é™¤é”™è¯¯
                print(f"[é”™è¯¯] åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç»§ç»­åˆ›å»ºæ–°æ–‡ä»¶

        # æ­¥éª¤3: ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»å†…å®¹
        news_content = generate_mock_news()

        # æ­¥éª¤4: åˆ›å»ºæ–°æ–‡ä»¶
        # ä½¿ç”¨æ—¶é—´æˆ³ + å¾®ç§’ + éšæœºæ•°ç¡®ä¿æ–‡ä»¶åå”¯ä¸€æ€§ï¼ˆé«˜å¹¶å‘åœºæ™¯ï¼‰
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        new_filename = f"news_{timestamp}.txt"
        filepath = os.path.join(FILE_DIR, new_filename)

        # æ­¥éª¤5: å¼‚æ­¥å†™å…¥æ–‡ä»¶
        try:
            async with aiofiles.open(filepath, 'w', encoding='utf-8') as f:
                await f.write(news_content)
            print(f"[å¹¶å‘åˆ›å»º] åˆ›å»ºæ–°æ–‡ä»¶: {new_filename}")
        except Exception as e:
            print(f"[é”™è¯¯] å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"å†™å…¥æ–‡ä»¶å¤±è´¥: {str(e)}"
            )

        # æ­¥éª¤6: è·å–æœ€æ–°æ–‡ä»¶æ•°é‡
        current_files = await get_files_sorted_by_mtime()

        # æ­¥éª¤7: è¿”å›ç»“æœ
        return {
            "status": "success",
            "message": "æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼ˆæ— é”å¹¶å‘æ¨¡å¼ï¼‰",
            "filename": new_filename,
            "deleted_file": deleted_file,
            "current_count": len(current_files),
            "max_files": MAX_FILES,
            "note": "é«˜å¹¶å‘åœºæ™¯ä¸‹æ–‡ä»¶æ•°é‡å¯èƒ½æš‚æ—¶è¶…è¿‡é™åˆ¶",
            "timestamp": datetime.now().isoformat()
        }

    except HTTPException:
        # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸
        raise
    except Exception as e:
        # æ•è·å…¶ä»–æ‰€æœ‰å¼‚å¸¸
        print(f"[é”™è¯¯] æ“ä½œå¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æ“ä½œå¤±è´¥: {str(e)}"
        )


@app.post("/search")
async def google_search():
    """
    ä½¿ç”¨æµè§ˆå™¨è®¿é—® Google å¹¶è¿›è¡Œéšæœºæœç´¢

    åŠŸèƒ½ï¼š
    1. å¯åŠ¨ Chromium æµè§ˆå™¨ï¼ˆæ— å¤´æ¨¡å¼ï¼‰
    2. è®¿é—® www.google.com
    3. éšæœºé€‰æ‹©ä¸€ä¸ªå…³é”®è¯è¿›è¡Œæœç´¢
    4. è·å–æœç´¢ç»“æœé¡µé¢æ ‡é¢˜
    5. å…³é—­æµè§ˆå™¨

    Returns:
        dict: æœç´¢ç»“æœä¿¡æ¯
    """
    search_keyword = random.choice(SEARCH_KEYWORDS)
    start_time = datetime.now()

    try:
        async with async_playwright() as p:
            # å¯åŠ¨æµè§ˆå™¨ï¼ˆä½¿ç”¨ç³»ç»Ÿ chromiumï¼‰
            print(f"[æµè§ˆå™¨] å¯åŠ¨ Chromium æµè§ˆå™¨...")
            browser = await p.chromium.launch(
                headless=True,
                args=[
                    '--no-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-blink-features=AutomationControlled'
                ]
            )

            # åˆ›å»ºæ–°é¡µé¢
            page = await browser.new_page()
            print(f"[æµè§ˆå™¨] è®¿é—® Google...")

            try:
                # è®¿é—® Google
                await page.goto('https://www.google.com', timeout=30000)
                await asyncio.sleep(1)

                # æŸ¥æ‰¾æœç´¢æ¡†å¹¶è¾“å…¥å…³é”®è¯
                print(f"[æµè§ˆå™¨] æœç´¢å…³é”®è¯: {search_keyword}")
                search_box = await page.query_selector('textarea[name="q"]')
                if not search_box:
                    # å°è¯•å¦ä¸€ä¸ªé€‰æ‹©å™¨
                    search_box = await page.query_selector('input[name="q"]')

                if search_box:
                    await search_box.fill(search_keyword)
                    await search_box.press('Enter')

                    # ç­‰å¾…æœç´¢ç»“æœåŠ è½½
                    await page.wait_for_load_state('networkidle', timeout=10000)
                    await asyncio.sleep(1)

                    # è·å–é¡µé¢æ ‡é¢˜
                    page_title = await page.title()
                    page_url = page.url

                    print(f"[æµè§ˆå™¨] æœç´¢å®Œæˆ: {page_title}")

                    # å…³é—­æµè§ˆå™¨
                    await browser.close()

                    end_time = datetime.now()
                    duration = (end_time - start_time).total_seconds()

                    return {
                        "status": "success",
                        "message": "æµè§ˆå™¨æœç´¢å®Œæˆ",
                        "search_keyword": search_keyword,
                        "page_title": page_title,
                        "page_url": page_url,
                        "duration_seconds": round(duration, 2),
                        "timestamp": datetime.now().isoformat()
                    }
                else:
                    await browser.close()
                    raise HTTPException(
                        status_code=500,
                        detail="æ— æ³•æ‰¾åˆ°æœç´¢æ¡†"
                    )

            except Exception as e:
                await browser.close()
                print(f"[æµè§ˆå™¨é”™è¯¯] {e}")
                raise HTTPException(
                    status_code=500,
                    detail=f"æµè§ˆå™¨æ“ä½œå¤±è´¥: {str(e)}"
                )

    except Exception as e:
        print(f"[é”™è¯¯] æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {str(e)}"
        )


@app.post("/terminal")
async def execute_terminal_command():
    """
    æ‰§è¡Œéšæœºç»ˆç«¯å‘½ä»¤

    åŠŸèƒ½ï¼š
    1. ä»é¢„å®šä¹‰å‘½ä»¤åˆ—è¡¨ä¸­éšæœºé€‰æ‹©ä¸€ä¸ªå‘½ä»¤
    2. åœ¨å­è¿›ç¨‹ä¸­æ‰§è¡Œè¯¥å‘½ä»¤
    3. æ•è·å‘½ä»¤è¾“å‡ºï¼ˆstdout å’Œ stderrï¼‰
    4. è¿”å›æ‰§è¡Œç»“æœ

    Returns:
        dict: å‘½ä»¤æ‰§è¡Œç»“æœ
    """
    # éšæœºé€‰æ‹©ä¸€ä¸ªå‘½ä»¤
    command_info = random.choice(TERMINAL_COMMANDS)
    command = command_info["cmd"]
    description = command_info["description"]

    start_time = datetime.now()

    try:
        print(f"[ç»ˆç«¯] æ‰§è¡Œå‘½ä»¤: {' '.join(command)}")

        # å¼‚æ­¥æ‰§è¡Œå‘½ä»¤
        process = await asyncio.create_subprocess_exec(
            *command,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE,
            cwd="/home/ubuntu"
        )

        # ç­‰å¾…å‘½ä»¤å®Œæˆå¹¶è·å–è¾“å‡º
        stdout, stderr = await process.communicate()

        # è§£ç è¾“å‡º
        stdout_text = stdout.decode('utf-8') if stdout else ""
        stderr_text = stderr.decode('utf-8') if stderr else ""

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        print(f"[ç»ˆç«¯] å‘½ä»¤æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç : {process.returncode}")

        return {
            "status": "success" if process.returncode == 0 else "error",
            "message": "ç»ˆç«¯å‘½ä»¤æ‰§è¡Œå®Œæˆ",
            "command": " ".join(command),
            "description": description,
            "return_code": process.returncode,
            "stdout": stdout_text.strip(),
            "stderr": stderr_text.strip() if stderr_text else None,
            "duration_seconds": round(duration, 3),
            "timestamp": datetime.now().isoformat()
        }

    except FileNotFoundError:
        print(f"[ç»ˆç«¯é”™è¯¯] å‘½ä»¤ä¸å­˜åœ¨: {command[0]}")
        raise HTTPException(
            status_code=500,
            detail=f"å‘½ä»¤ä¸å­˜åœ¨: {command[0]}"
        )
    except Exception as e:
        print(f"[ç»ˆç«¯é”™è¯¯] æ‰§è¡Œå¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"
        )


@app.post("/network")
async def network_io_test():
    """
    æ‰§è¡Œç½‘ç»œ I/O æµ‹è¯•

    åŠŸèƒ½ï¼š
    1. éšæœºé€‰æ‹©ä¸€ä¸ªæµ‹è¯• URL
    2. å‘é€ HTTP è¯·æ±‚å¹¶ä¸‹è½½æ•°æ®
    3. æµ‹é‡ç½‘ç»œå»¶è¿Ÿã€ä¸‹è½½é€Ÿåº¦
    4. å¯é€‰ï¼šå‘é€å¤šä¸ªå¹¶å‘è¯·æ±‚

    Returns:
        dict: ç½‘ç»œæµ‹è¯•ç»“æœ
    """
    # éšæœºé€‰æ‹©æµ‹è¯•é…ç½®
    test_config = random.choice(NETWORK_TEST_URLS)
    url = test_config["url"]
    description = test_config["description"]
    expected_size_mb = test_config["size_mb"]

    start_time = datetime.now()

    try:
        print(f"[ç½‘ç»œ] å¼€å§‹æµ‹è¯•: {description}")
        print(f"[ç½‘ç»œ] URL: {url}")

        async with httpx.AsyncClient(timeout=30.0) as client:
            # å‘é€è¯·æ±‚å¹¶ä¸‹è½½æ•°æ®
            response = await client.get(url)

            # è·å–å“åº”æ•°æ®
            data = response.content
            data_size_bytes = len(data)
            data_size_mb = data_size_bytes / (1024 * 1024)

            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()

            # è®¡ç®—ä¸‹è½½é€Ÿåº¦
            if duration > 0:
                speed_mbps = (data_size_mb * 8) / duration  # Mbps
            else:
                speed_mbps = 0

            print(f"[ç½‘ç»œ] å®Œæˆ: {data_size_mb:.2f} MB, {duration:.2f}s, {speed_mbps:.2f} Mbps")

            return {
                "status": "success",
                "message": "ç½‘ç»œ I/O æµ‹è¯•å®Œæˆ",
                "test_description": description,
                "url": url,
                "http_status": response.status_code,
                "data_size_mb": round(data_size_mb, 3),
                "expected_size_mb": expected_size_mb,
                "duration_seconds": round(duration, 3),
                "download_speed_mbps": round(speed_mbps, 2),
                "timestamp": datetime.now().isoformat()
            }

    except httpx.TimeoutException:
        print(f"[ç½‘ç»œé”™è¯¯] è¯·æ±‚è¶…æ—¶: {url}")
        raise HTTPException(
            status_code=504,
            detail=f"ç½‘ç»œè¯·æ±‚è¶…æ—¶: {url}"
        )
    except httpx.RequestError as e:
        print(f"[ç½‘ç»œé”™è¯¯] è¯·æ±‚å¤±è´¥: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
        )
    except Exception as e:
        print(f"[ç½‘ç»œé”™è¯¯] æœªçŸ¥é”™è¯¯: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"ç½‘ç»œæµ‹è¯•å¤±è´¥: {str(e)}"
        )


@app.post("/network/concurrent")
async def network_concurrent_test(num_requests: int = 5):
    """
    æ‰§è¡Œå¹¶å‘ç½‘ç»œ I/O æµ‹è¯•

    Args:
        num_requests: å¹¶å‘è¯·æ±‚æ•°é‡ï¼ˆé»˜è®¤ 5ï¼‰

    åŠŸèƒ½ï¼š
    1. åŒæ—¶å‘é€å¤šä¸ª HTTP è¯·æ±‚
    2. æµ‹é‡æ€»ä½“ååé‡å’Œå¹³å‡å»¶è¿Ÿ
    3. ç»Ÿè®¡æˆåŠŸç‡

    Returns:
        dict: å¹¶å‘æµ‹è¯•ç»“æœ
    """
    if num_requests < 1 or num_requests > 50:
        raise HTTPException(
            status_code=400,
            detail="num_requests å¿…é¡»åœ¨ 1-50 ä¹‹é—´"
        )

    print(f"[ç½‘ç»œ] å¼€å§‹å¹¶å‘æµ‹è¯•: {num_requests} ä¸ªè¯·æ±‚")
    start_time = datetime.now()

    # åˆ›å»ºæµ‹è¯•ä»»åŠ¡
    async def single_request(request_id: int) -> dict:
        test_config = random.choice(NETWORK_TEST_URLS)
        url = test_config["url"]

        req_start = datetime.now()
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.get(url)
                data_size = len(response.content)
                req_duration = (datetime.now() - req_start).total_seconds()

                return {
                    "request_id": request_id,
                    "success": True,
                    "url": url,
                    "status": response.status_code,
                    "size_bytes": data_size,
                    "duration": req_duration
                }
        except Exception as e:
            return {
                "request_id": request_id,
                "success": False,
                "url": url,
                "error": str(e)
            }

    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰è¯·æ±‚
    tasks = [single_request(i) for i in range(num_requests)]
    results = await asyncio.gather(*tasks)

    end_time = datetime.now()
    total_duration = (end_time - start_time).total_seconds()

    # ç»Ÿè®¡ç»“æœ
    successful_requests = [r for r in results if r.get("success")]
    failed_requests = [r for r in results if not r.get("success")]

    total_bytes = sum(r.get("size_bytes", 0) for r in successful_requests)
    total_mb = total_bytes / (1024 * 1024)

    avg_latency = sum(r.get("duration", 0) for r in successful_requests) / len(successful_requests) if successful_requests else 0

    throughput_mbps = (total_mb * 8) / total_duration if total_duration > 0 else 0

    print(f"[ç½‘ç»œ] å¹¶å‘æµ‹è¯•å®Œæˆ: {len(successful_requests)}/{num_requests} æˆåŠŸ")

    return {
        "status": "success",
        "message": "å¹¶å‘ç½‘ç»œæµ‹è¯•å®Œæˆ",
        "num_requests": num_requests,
        "successful_requests": len(successful_requests),
        "failed_requests": len(failed_requests),
        "success_rate_percent": round((len(successful_requests) / num_requests) * 100, 2),
        "total_data_mb": round(total_mb, 3),
        "total_duration_seconds": round(total_duration, 3),
        "average_latency_seconds": round(avg_latency, 3),
        "throughput_mbps": round(throughput_mbps, 2),
        "timestamp": datetime.now().isoformat()
    }


@app.get("/load/status")
async def get_load_status():
    """
    è·å–è´Ÿè½½æµ‹è¯•æœåŠ¡çŠ¶æ€

    é€šè¿‡è¯»å–è´Ÿè½½æ§åˆ¶æœåŠ¡çš„çŠ¶æ€æ–‡ä»¶è·å–ä¿¡æ¯

    Returns:
        dict: è´Ÿè½½æµ‹è¯•æœåŠ¡çŠ¶æ€
    """
    try:
        # å°è¯•è¯»å–çŠ¶æ€æ–‡ä»¶
        status_file = "/tmp/load_controller_status.json"
        if os.path.exists(status_file):
            async with aiofiles.open(status_file, 'r') as f:
                import json
                content = await f.read()
                return json.loads(content)
        else:
            return {
                "status": "unknown",
                "message": "è´Ÿè½½æ§åˆ¶æœåŠ¡çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨"
            }
    except Exception as e:
        return {
            "status": "error",
            "message": f"è·å–çŠ¶æ€å¤±è´¥: {str(e)}"
        }


@app.post("/load/target")
async def set_load_target(target_cpu: float):
    """
    è®¾ç½®ç›®æ ‡ CPU ä½¿ç”¨ç‡

    Args:
        target_cpu: ç›®æ ‡ CPU ä½¿ç”¨ç‡ (0-100)

    Returns:
        dict: è®¾ç½®ç»“æœ
    """
    if not 0 <= target_cpu <= 100:
        raise HTTPException(
            status_code=400,
            detail="target_cpu å¿…é¡»åœ¨ 0-100 ä¹‹é—´"
        )

    try:
        # å†™å…¥é…ç½®æ–‡ä»¶
        config_file = "/tmp/load_controller_config.json"
        config = {
            "target_cpu": target_cpu,
            "updated_at": datetime.now().isoformat()
        }

        async with aiofiles.open(config_file, 'w') as f:
            import json
            await f.write(json.dumps(config, indent=2))

        print(f"[è´Ÿè½½æ§åˆ¶] ç›®æ ‡ CPU ä½¿ç”¨ç‡å·²æ›´æ–°: {target_cpu}%")

        return {
            "status": "success",
            "message": f"ç›®æ ‡ CPU ä½¿ç”¨ç‡å·²è®¾ç½®ä¸º {target_cpu}%",
            "target_cpu": target_cpu,
            "note": "è´Ÿè½½æ§åˆ¶æœåŠ¡å°†åœ¨ä¸‹ä¸€ä¸ªè°ƒæ•´å‘¨æœŸï¼ˆ~5ç§’ï¼‰åº”ç”¨æ–°é…ç½®"
        }

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"è®¾ç½®å¤±è´¥: {str(e)}"
        )


@app.get("/")
async def root():
    """
    æ ¹è·¯å¾„ï¼Œè¿”å›æœåŠ¡ä¿¡æ¯

    Returns:
        dict: æœåŠ¡åŸºæœ¬ä¿¡æ¯å’Œå¯ç”¨æ¥å£
    """
    return {
        "service": "æ–‡ä»¶ç®¡ç†æœåŠ¡",
        "version": "1.0.0",
        "endpoints": {
            "/health": "å¥åº·æ£€æŸ¥ (GET)",
            "/sum": "è·å–æ–‡ä»¶æ•°é‡ (GET)",
            "/action": "åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥æ–°é—» (POST)",
            "/search": "æµè§ˆå™¨æœç´¢ (POST)",
            "/terminal": "æ‰§è¡Œç»ˆç«¯å‘½ä»¤ (POST)",
            "/network": "ç½‘ç»œ I/O æµ‹è¯• (POST)",
            "/network/concurrent": "å¹¶å‘ç½‘ç»œæµ‹è¯• (POST)",
            "/load/status": "è·å–è´Ÿè½½æµ‹è¯•çŠ¶æ€ (GET)",
            "/load/target": "è®¾ç½®ç›®æ ‡è´Ÿè½½ (POST)",
            "/docs": "APIæ–‡æ¡£ (GET)"
        },
        "description": "åŸºäºFastAPIçš„å¼‚æ­¥æ–‡ä»¶ç®¡ç†æœåŠ¡ï¼Œæ”¯æŒå¹¶å‘å®‰å…¨æ“ä½œã€æµè§ˆå™¨è‡ªåŠ¨åŒ–ã€ç»ˆç«¯å‘½ä»¤æ‰§è¡Œã€ç½‘ç»œ I/O æµ‹è¯•å’ŒåŠ¨æ€è´Ÿè½½æ§åˆ¶"
    }


# å¯åŠ¨æ—¶çš„åˆå§‹åŒ–
@app.on_event("startup")
async def startup_event():
    """
    åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œ
    ç¡®ä¿å·¥ä½œç›®å½•å­˜åœ¨ï¼Œå®‰è£… Playwright æµè§ˆå™¨
    """
    print("=" * 50)
    print("æ–‡ä»¶ç®¡ç†æœåŠ¡å¯åŠ¨ä¸­...")
    print(f"å·¥ä½œç›®å½•: {FILE_DIR}")
    print(f"æœ€å¤§æ–‡ä»¶æ•°: {MAX_FILES}")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    try:
        Path(FILE_DIR).mkdir(parents=True, exist_ok=True)
        print(f"å·¥ä½œç›®å½•å·²å°±ç»ª")
    except Exception as e:
        print(f"åˆ›å»ºå·¥ä½œç›®å½•å¤±è´¥: {e}")

    # æ˜¾ç¤ºå½“å‰æ–‡ä»¶æ•°é‡
    files = await get_files_sorted_by_mtime()
    print(f"å½“å‰æ–‡ä»¶æ•°é‡: {len(files)}")
    print("=" * 50)


@app.on_event("shutdown")
async def shutdown_event():
    """
    åº”ç”¨å…³é—­æ—¶æ‰§è¡Œ
    """
    print("=" * 50)
    print("æ–‡ä»¶ç®¡ç†æœåŠ¡æ­£åœ¨å…³é—­...")
    print("=" * 50)


if __name__ == "__main__":
    import uvicorn

    # å¼€å‘ç¯å¢ƒè¿è¡Œé…ç½®
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8080,
        log_level="info"
    )
